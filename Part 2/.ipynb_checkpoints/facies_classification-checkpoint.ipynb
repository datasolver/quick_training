{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./csv_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '15_9-13.csv'\n",
    "train_and_validate = pd.read_csv(filename)\n",
    "train_and_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['CALI', 'DRHO', 'PEF','DTE', 'RSHA', 'RXO', 'RMED']\n",
    "train_and_validate = train_and_validate.drop(columns = drop_col)\n",
    "train_and_validate = train_and_validate.dropna()\n",
    "train_and_validate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate = train_and_validate[(train_and_validate.NPHI <=0.5) & (train_and_validate.RHOB >=2) \n",
    "                                & (train_and_validate.RHOB <=3) & (train_and_validate.GR <= 200)]\n",
    "train_and_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate.LITHOLOGY_GEOLINK.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithofacies = open('../litho_nomenclatures.txt').readlines()\n",
    "lithofacies = [line.strip().replace('\\n', '') for line in lithofacies]\n",
    "lithofacies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ['#76eec6','#ffebcd','#0000ff','#a52a2a','#ff4040','#deb887','#98f5ff','#7fff00','#458b00','#ff7f24',\n",
    "           '#eee8cd','#00ffff','#ffb90f','#006400','#caff70','#9932cc','#1e90ff','#b22222','#ffd700','#bebebe',\n",
    "           '#f0e68c','#add8e6','#a4d3ee','#ffffe0','#ff34b3','#ab82ff','#ffe4e1','#ff83fa', '#8b475d','#ffdab9',\n",
    "           '#ff0000','#f4a460','#d8bfd8','#ffe1ff','#ffff00', '#9acd32']\n",
    "\n",
    "facies_by_color = dict(zip(lithofacies, colours))\n",
    "facies_colors = facies_by_color.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_plotter(logs, facies_colors):\n",
    "    #make sure logs are sorted by DEPT\n",
    "    logs = logs.sort_values(by='DEPT')\n",
    "    cmap_facies = mcolors.ListedColormap(facies_colors, 'indexed')\n",
    "    \n",
    "    ztop=logs.DEPT.min(); zbot=logs.DEPT.max()\n",
    "    \n",
    "    cluster=np.repeat(np.expand_dims(logs['LITHOLOGY_GEOLINK'].values,1), 100, 1)\n",
    "    #columns = logs.columns[2:]\n",
    "    #ncolumns = len(columns)\n",
    "    #log_colors = [\"black\", \"blue\", \"green\", \"red\", \"purple\", \"brown\", \"cyan\", \"magenta\", \"grey\"]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=7, figsize=(8, 14))\n",
    "    \n",
    "    ax[0].plot(logs.NPHI, logs.DEPT, '-g')\n",
    "    ax[1].plot(logs.RHOB, logs.DEPT, '-')\n",
    "    ax[2].plot(logs.GR, logs.DEPT, '-', color='0.5')\n",
    "    ax[3].plot(logs.DTC, logs.DEPT, '-', color='r')\n",
    "    ax[4].plot(logs.RDEP, logs.DEPT, '-', color='b')\n",
    "    ax[5].plot(logs.SP, logs.DEPT, '-', color='black')\n",
    "    \n",
    "    im=ax[6].imshow(cluster, interpolation='none', aspect='auto', cmap=cmap_facies,vmin=1,vmax=len(facies_colors))\n",
    "    \"\"\"\n",
    "    for ind in range(ncolumns):\n",
    "        if columns[ind] != 'LITHOLOGY_GEOLINK':\n",
    "            ax[ind].plot(logs[columns[ind]], logs.DEPT, color = log_colors[ind])\n",
    "            ax[ind].set_yticklabels([])\n",
    "            ax[ind].set_xlabel(columns[ind])\n",
    "            ax[ind].set_xlim(logs[columns[ind]].min(),logs[columns[ind]].max())\n",
    "            #ax[0].set_ylim(ztop,zbot)\n",
    "            #ax[0].invert_yaxis() \n",
    "        im=ax[-1].imshow(cluster, interpolation='none', aspect='auto', cmap=cmap_facies,vmin=1,vmax=9)\n",
    "        ax[-1].set_xlabel('Facies'); ax[-1].set_xticklabels([])\n",
    "    \"\"\"\n",
    "    divider = make_axes_locatable(ax[6])\n",
    "    cax = divider.append_axes(\"right\", size=\"10%\", pad=0.05)\n",
    "    cbar=plt.colorbar(im, cax=cax)\n",
    "    cbar.set_label((2*' ').join(lithofacies))\n",
    "    #cbar.set_label(lithofacies)\n",
    "    cbar.set_ticks(range(0,1)); cbar.set_ticklabels('')\n",
    "    \"\"\"    \n",
    "    cbar.ax.get_yaxis().set_ticks([])\n",
    "    for j, lab in enumerate(lithofacies):\n",
    "        cbar.ax.text(.5, (2 * j + 1) / 8.0, lab)#, ha='center', va='center')\n",
    "    cbar.ax.get_yaxis().labelpad = 15\n",
    "    #cbar.ax[6].set_ylabel('# of contacts', rotation=270)\n",
    "    \"\"\"    \n",
    "    for i in range(len(ax)):\n",
    "        ax[i].set_ylim(ztop,zbot)\n",
    "        ax[i].invert_yaxis()\n",
    "        ax[i].grid()\n",
    "        ax[i].locator_params(axis='x', nbins=3)\n",
    "    \n",
    "    ax[0].set_xlabel(\"NPHI\")\n",
    "    ax[0].set_xlim(logs.NPHI.min(),logs.NPHI.max())\n",
    "    ax[1].set_xlabel(\"RHOB\")\n",
    "    ax[1].set_xlim(logs.RHOB.min(),logs.RHOB.max())\n",
    "    ax[2].set_xlabel(\"GR\")\n",
    "    ax[2].set_xlim(logs.GR.min(),logs.GR.max())\n",
    "    ax[3].set_xlabel(\"DTC\")\n",
    "    ax[3].set_xlim(logs.DTC.min(),logs.DTC.max())\n",
    "    ax[4].set_xlabel(\"RDEP\")\n",
    "    ax[4].set_xlim(logs.RDEP.min(),logs.RDEP.max())   \n",
    "    ax[5].set_xlabel(\"SP\")\n",
    "    ax[5].set_xlim(logs.SP.min(),logs.SP.max()) \n",
    "    ax[6].set_xlabel('lithofacies')\n",
    "    \n",
    "    ax[1].set_yticklabels([]); ax[2].set_yticklabels([]); ax[3].set_yticklabels([])\n",
    "    ax[4].set_yticklabels([]); ax[5].set_yticklabels([]); ax[6].set_yticklabels([])\n",
    "    ax[6].set_xticklabels([])\n",
    "    \n",
    "    fig.suptitle('Well: %s'%filename.split('.')[0], fontsize=14, y=0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_plotter( train_and_test, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lithofacies_counts = train_and_test['LITHOLOGY_GEOLINK'].value_counts().sort_index()\n",
    "new_index = list(range(1, len(lithofacies)+1))\n",
    "\n",
    "available_facies = [facie for i, facie in zip(new_index, lithofacies) if i in lithofacies_counts.index]\n",
    "\n",
    "lithofacies_counts.index = available_facies\n",
    "\n",
    "lithofacies_counts.plot(kind='bar', color = facies_colors, title='Available Facies Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithofacies_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_facies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_facies_labels = train_and_test['LITHOLOGY_GEOLINK'].values\n",
    "\n",
    "feature_vectors = train_and_test.drop(['DEPT','LITHOLOGY_GEOLINK'], axis=1)\n",
    "feature_vectors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(feature_vectors)\n",
    "scaled_features = scaler.transform(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, correct_facies_labels, \n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_test, predicted_labels)\n",
    "#display_cm(conf, facies_labels, hide_zeros=True)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "\n",
    "    np.set_printoptions(precision=2)\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "disp = plot_confusion_matrix(conf, target_names=available_facies, cmap=plt.cm.Blues, normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clf.score(X_test, y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result*100.0))\n",
    "print(\"F1 Score: \", f1_score(y_test, predicted_labels, average=\"macro\"))\n",
    "print(\"Precision Score: \", precision_score(y_test, predicted_labels, average=\"macro\"))\n",
    "print(\"Recall Score: \", recall_score(y_test, predicted_labels, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain what each metric means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def cm_analysis(y_true, y_pred, labels, ymap=None, figsize=(10,10)):\n",
    "    \"\"\"\n",
    "    Generate matrix plot of confusion matrix with pretty annotations.\n",
    "    The plot image is saved to disk.\n",
    "    args: \n",
    "      y_true:    true label of the data, with shape (nsamples,)\n",
    "      y_pred:    prediction of the data, with shape (nsamples,)\n",
    "      filename:  filename of figure file to save\n",
    "      labels:    string array, name the order of class labels in the confusion matrix.\n",
    "                 use `clf.classes_` if using scikit-learn models.\n",
    "                 with shape (nclass,).\n",
    "      ymap:      dict: any -> string, length == nclass.\n",
    "                 if not None, map the labels & ys to more understandable strings.\n",
    "                 Caution: original y_true, y_pred and labels must align.\n",
    "      figsize:   the size of the figure plotted.\n",
    "    \"\"\"\n",
    "    if ymap is not None:\n",
    "        y_pred = [ymap[yi] for yi in y_pred]\n",
    "        y_true = [ymap[yi] for yi in y_true]\n",
    "        labels = [ymap[yi] for yi in labels]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=annot, fmt='', ax=ax)\n",
    "    #plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "cm_analysis(y_test, predicted_labels, clf.classes_, ymap=None, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a similar plot as above but including the predicted facies\n",
    "# include validation with 1 well containing the same set of logs and facies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
